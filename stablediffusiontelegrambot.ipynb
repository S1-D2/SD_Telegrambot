{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c5f36474c024a22840e66bf72bda262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4a99340f2344856884d3bbed0af72f6",
              "IPY_MODEL_c4a2fe8e19ae4e2eb7ada4de0ca60562",
              "IPY_MODEL_9e973b4b00ef4f2296767d4d817a79d0",
              "IPY_MODEL_2f6a1c29361047bcb076938badffce8f"
            ],
            "layout": "IPY_MODEL_0c83eb4dad184079983b9bcf7d309fe7"
          }
        },
        "c4a99340f2344856884d3bbed0af72f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e6839aff2a4885ae3f7c6b81d41091",
            "placeholder": "​",
            "style": "IPY_MODEL_09c967fe0f5347b2b0716bd9bdd19abb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c4a2fe8e19ae4e2eb7ada4de0ca60562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8ddca881fa0d47838a7ea042ac8e2d5d",
            "placeholder": "​",
            "style": "IPY_MODEL_d99a823d7c3f4cc690bc6382ef099187",
            "value": ""
          }
        },
        "9e973b4b00ef4f2296767d4d817a79d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a7bcc10873b9441ba179b626d7defec0",
            "style": "IPY_MODEL_a85ef57e466a4bed933e2e3d424f1bcd",
            "tooltip": ""
          }
        },
        "2f6a1c29361047bcb076938badffce8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3e8d1469474b8181c19ff0ceb9c4fc",
            "placeholder": "​",
            "style": "IPY_MODEL_0762e96b8dda44479c4ff174aa59319b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "0c83eb4dad184079983b9bcf7d309fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "68e6839aff2a4885ae3f7c6b81d41091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c967fe0f5347b2b0716bd9bdd19abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ddca881fa0d47838a7ea042ac8e2d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99a823d7c3f4cc690bc6382ef099187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7bcc10873b9441ba179b626d7defec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85ef57e466a4bed933e2e3d424f1bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9a3e8d1469474b8181c19ff0ceb9c4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0762e96b8dda44479c4ff174aa59319b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrZilheiM6lC",
        "outputId": "dcc32e72-4817-411f-a75b-7038323fe6d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 24 02:02:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrEOZtWwMwWS",
        "outputId": "9dde519f-9a6c-4f0b-b4d6-39dd430441dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StableDiffusionTelegram'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 49 (delta 4), reused 4 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jossalgon/StableDiffusionTelegram.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vzMZXnnNEQb",
        "outputId": "fce0b993-5594-4a79-cab6-be603fc43636"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd StableDiffusionTelegram && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi7Z09u-NHQI",
        "outputId": "b30bd6c3-65a6-4f70-80b2-0243b53c2f19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers==0.7.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: transformers==4.24.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.24.0)\n",
            "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (6.1.1)\n",
            "Requirement already satisfied: python-telegram-bot>=20.0a2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (20.0b0)\n",
            "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: huggingface_hub==0.10.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: Pillow<10.0 in /usr/local/lib/python3.8/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (5.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (4.64.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub==0.10.1->-r requirements.txt (line 7)) (4.4.0)\n",
            "Requirement already satisfied: httpx~=0.23.1 in /usr/local/lib/python3.8/dist-packages (from python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (0.23.1)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (0.16.3)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.8/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (3.6.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx~=0.23.1->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.24.0->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->diffusers==0.7.2->-r requirements.txt (line 1)) (3.11.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.7.2->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.7.2->-r requirements.txt (line 1)) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "3c5f36474c024a22840e66bf72bda262",
            "c4a99340f2344856884d3bbed0af72f6",
            "c4a2fe8e19ae4e2eb7ada4de0ca60562",
            "9e973b4b00ef4f2296767d4d817a79d0",
            "2f6a1c29361047bcb076938badffce8f",
            "0c83eb4dad184079983b9bcf7d309fe7",
            "68e6839aff2a4885ae3f7c6b81d41091",
            "09c967fe0f5347b2b0716bd9bdd19abb",
            "8ddca881fa0d47838a7ea042ac8e2d5d",
            "d99a823d7c3f4cc690bc6382ef099187",
            "a7bcc10873b9441ba179b626d7defec0",
            "a85ef57e466a4bed933e2e3d424f1bcd",
            "9a3e8d1469474b8181c19ff0ceb9c4fc",
            "0762e96b8dda44479c4ff174aa59319b"
          ]
        },
        "id": "YCXFpbnDNdR8",
        "outputId": "af1e8558-3f31-45b7-e2e9-4d815f7020b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TG_TOKEN = '5831287065:AAFPinzf8ZR__fX18Qq_ka5ZaN22bRjB4po'"
      ],
      "metadata": {
        "id": "jRa4qm7cPNNj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!printf \"TG_TOKEN='{TG_TOKEN}'\\nSAFETY_CHECKER='false'\" > StableDiffusionTelegram/.env"
      ],
      "metadata": {
        "id": "yXblRtBjNh65"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat StableDiffusionTelegram/.env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27monR3JOYtz",
        "outputId": "c9854ba5-2f21-4d10-b896-124ad470079d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TG_TOKEN='5831287065:AAFPinzf8ZR__fX18Qq_ka5ZaN22bRjB4po'\n",
            "SAFETY_CHECKER='false'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B2TR9NczkdA",
        "outputId": "5b70a9d5-1351-4c2e-c847-16238ed147c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python StableDiffusionTelegram/sidbot.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZSvSocMOvc1",
        "outputId": "d7bf3af2-5981-46c1-8c05-8c3e1f05ff07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 15 files:   0% 0/15 [00:00<?, ?it/s]\rFetching 15 files: 100% 15/15 [00:00<00:00, 4179.54it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Fetching 15 files: 100% 15/15 [00:00<00:00, 30364.17it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 41/41 [00:11<00:00,  3.48it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 17/17 [00:04<00:00,  3.91it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 17/17 [00:04<00:00,  3.86it/s]\n"
          ]
        }
      ]
    }
  ]
}